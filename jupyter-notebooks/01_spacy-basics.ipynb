{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4368a89d",
   "metadata": {},
   "source": [
    "# spaCy Basics\n",
    "\n",
    "**spaCy** (https://spacy.io/) is an open-source Python library that parses and \"understands\" large volumes of text. Separate models are available that cater to specific languages (English, French, German, etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c05f2392",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf4c8b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5ff6b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u'Tesla is looking at buying U.S. startup for $6 million')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fa83de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token\t\t part of speech\t\t part of speech (raw)\t\t syntactic dependency\t\t\n",
      "Tesla                   96                     PROPN                               nsubj\n",
      "is                      87                       AUX                                 aux\n",
      "looking                100                      VERB                                ROOT\n",
      "at                      85                       ADP                                prep\n",
      "buying                 100                      VERB                               pcomp\n",
      "U.S.                    96                     PROPN                            compound\n",
      "startup                 92                      NOUN                                dobj\n",
      "for                     85                       ADP                                prep\n",
      "$                       99                       SYM                            quantmod\n",
      "6                       93                       NUM                            compound\n",
      "million                 93                       NUM                                pobj\n"
     ]
    }
   ],
   "source": [
    "print('token\\t\\t', 'part of speech\\t\\t', 'part of speech (raw)\\t\\t', 'syntactic dependency\\t\\t')\n",
    "\n",
    "for token in doc:\n",
    "    print(f\"{token.text:{15}} {token.pos:>{10}} {token.pos_:>{25}} {token.dep_:>{35}}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57823b33",
   "metadata": {},
   "source": [
    "**Universal POS tags** - https://universaldependencies.org/u/pos/\n",
    "\n",
    "**Token attributes** - https://spacy.io/api/token#attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01836c8d",
   "metadata": {},
   "source": [
    "___\n",
    "# Pipeline\n",
    "When we run `nlp`, our text enters a *processing pipeline* that first breaks down the text and then performs a series of operations to tag, parse and describe the data.\n",
    "<img src=\"../images/spacy-processing-pipeline.svg\" width=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c6aea31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec at 0x1260728d0>),\n",
       " ('tagger', <spacy.pipeline.tagger.Tagger at 0x126072570>),\n",
       " ('parser', <spacy.pipeline.dep_parser.DependencyParser at 0x125f84cf0>),\n",
       " ('attribute_ruler',\n",
       "  <spacy.pipeline.attributeruler.AttributeRuler at 0x12622c510>),\n",
       " ('lemmatizer', <spacy.lang.en.lemmatizer.EnglishLemmatizer at 0x12621a690>),\n",
       " ('ner', <spacy.pipeline.ner.EntityRecognizer at 0x125f84d60>)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7f983ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla Tesla PROPN NNP nsubj Xxxxx True False\n",
      "is be AUX VBZ aux xx True True\n",
      "looking look VERB VBG ROOT xxxx True False\n",
      "at at ADP IN prep xx True True\n",
      "buying buy VERB VBG pcomp xxxx True False\n",
      "U.S. U.S. PROPN NNP compound X.X. False False\n",
      "startup startup NOUN NN dobj xxxx True False\n",
      "for for ADP IN prep xxx True True\n",
      "$ $ SYM $ quantmod $ False False\n",
      "6 6 NUM CD compound d False False\n",
      "million million NUM CD pobj xxxx True False\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_, token.shape_, token.is_alpha, token.is_stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff03b55",
   "metadata": {},
   "source": [
    "**Text**: The original word text.\n",
    "**Lemma**: The base form of the word.\n",
    "**POS**: The simple UPOS part-of-speech tag.\n",
    "**Tag**: The detailed part-of-speech tag.\n",
    "**Dep**: Syntactic dependency, i.e. the relation between tokens.\n",
    "**Shape**: The word shape â€“ capitalization, punctuation, digits.\n",
    "**is alpha**: Is the token an alpha character?\n",
    "**is stop**: Is the token part of a stop list, i.e. the most common words of the language?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be582ea8",
   "metadata": {},
   "source": [
    "Processing pipelines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06c268dd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b380fbd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token\t\t part of speech\t\t part of speech (raw)\t\t syntactic dependency\t\t\n",
      "Tesla                   96                     PROPN                               nsubj\n",
      "is                      87                       AUX                                 aux\n",
      "n't                     94                      PART                                 neg\n",
      "looking                100                      VERB                                ROOT\n",
      "into                    85                       ADP                                prep\n",
      "startups                92                      NOUN                                pobj\n",
      "anymore                 86                       ADV                              advmod\n",
      ".                       97                     PUNCT                               punct\n"
     ]
    }
   ],
   "source": [
    "doc2 = nlp(u\"Tesla isn't looking into startups anymore.\")\n",
    "\n",
    "print('token\\t\\t', 'part of speech\\t\\t', 'part of speech (raw)\\t\\t', 'syntactic dependency\\t\\t')\n",
    "\n",
    "for token in doc2:\n",
    "    print(f\"{token.text:{15}} {token.pos:>{10}} {token.pos_:>{25}} {token.dep_:>{35}}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5b2e2fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "green green PROPN NNP amod xxxx True False\n",
      "shirt shirt NOUN NN ROOT xxxx True False\n"
     ]
    }
   ],
   "source": [
    "doc3 = nlp(u\"green shirt\")\n",
    "\n",
    "for token in doc3:\n",
    "    print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_, token.shape_, token.is_alpha, token.is_stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc52032",
   "metadata": {},
   "source": [
    "___\n",
    "## Spans\n",
    "Large Doc objects can be hard to work with at times. A **span** is a slice of Doc object in the form `Doc[start:stop]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16a2725f",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc4 = nlp(u'Although commmonly attributed to John Lennon from his song \"Beautiful Boy\", \\\n",
    "the phrase \"Life is what happens to us while we are making other plans\" was written by \\\n",
    "cartoonist Allen Saunders and published in Reader\\'s Digest in 1957, when Lennon was 17.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1ed1974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Life is what happens to us while we are making other plans\"\n"
     ]
    }
   ],
   "source": [
    "life_quote = doc4[16:30]\n",
    "print(life_quote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e888d85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.span.Span"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(life_quote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40063ab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4f67d0",
   "metadata": {},
   "source": [
    "___\n",
    "## Sentences\n",
    "Certain tokens inside a Doc object may also receive a \"start of sentence\" tag. While this doesn't immediately build a list of sentences, these tags enable the generation of sentence segments through `Doc.sents`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67956636",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc5 = nlp(u'This is the first sentence. This is another sentence. This is the last sentence.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50d8b5bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the first sentence.\n",
      "This is another sentence.\n",
      "This is the last sentence.\n"
     ]
    }
   ],
   "source": [
    "for sent in doc5.sents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "409350bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc4[6].is_sent_start"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
